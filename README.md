# Delayed Feedback Modeling for Post-Click Gross Merchandise Volume Prediction: Benchmark, Insights and Approaches

[![Python](https://img.shields.io/badge/Python-3.8%2B-green)]()
[![PyTorch](https://img.shields.io/badge/Framework-PyTorch-orange)]()

This repository provides the code and benchmark for our WWW 2026 paper [*Delayed Feedback Modeling for Post-Click Gross Merchandise Volume Prediction: Benchmark, Insights and Approaches*](https://arxiv.org/pdf/2601.20307). 

We introduce **TRACE**, the first benchmark dataset for post-click GMV prediction with delayed feedback, and propose **READER**, a novel GMV prediction paradigm designed to handle the unique challenges of this problem.

## ğŸ“¦ Dataset

The experiments are based on a large-scale industrial dataset from Alibaba, capturing multi-stage user behaviors including click, add-to-cart, payment, and refund, with precise timestamps for modeling delay dynamics.

ğŸ‘‰ **Dataset Information**:  
TRACE Dataset on [HuggingFace](https://huggingface.co/datasets/alimamaTech/TRACE).

ğŸ“ Data structure includes:
1.  **Features**:
    *   **User/Item/Contextual Attributes**: 22 such attributes are provided (e.g., `feature_0` to `feature_21`).
    *   **Click Timestamp**: `click_time`.

2.  **Labels and Sequence Information**:
    *   **Gross Merchandise Volume (GMV) Sequence**: The sequence of transaction amounts for all purchases associated with a click. This is represented by `dirpay_amt` for the current purchase and `prev_dirpay_amt` for previous purchases.
    *   **Purchase Count Sequence**: The sequence indicating the order of each purchase within the attribution window for a given click. `count` represents the current purchase's order, and `total_counts` indicates the final number of purchases.
    *   **Purchase Timestamp Sequence**: The sequence of timestamps for each purchase. `pay_time` typically represents the timestamp of the current purchase, and `prev_pay_time` contains timestamps of previous purchases.
    *   **Repurchase Indicator (`multi_tag`)**: A binary label (0 or 1) indicating whether the GMV generated by a click is from a single purchase (0) or a repurchase (1). This is derived from the number of purchases.
    *   **Final Ground-Truth GMV Label**: The total GMV accumulated by the end of the attribution window. This is calculated as the sum of `dirpay_amt`.

### Data Loading and Preprocessing:

For ease of reproducibility and faster experimentation, the training data has been pre-processed and saved in `.pkl` (pickle) format. This allows for quick loading of the dataset without needing to re-run the entire preprocessing pipeline.

These files should be placed in the `data/` directory.

---

## ğŸ“ Project Structure

```bash
READER/
â”œâ”€â”€ data/               # data files
    â”œâ”€â”€ trace.txt
    â”œâ”€â”€ .pkl           
â”œâ”€â”€ log/                # Training logs and evaluation outputs
â”œâ”€â”€ method_src/         # Source code related to specific methods or components (e.g., READER)
â”œâ”€â”€ pretrian_model/     # Stores pre-trained model weights
â”œâ”€â”€ src/                # Source code related to specific methods or components (e.g., baselines)
â”œâ”€â”€ main.py             # Entry point for experiments
â”œâ”€â”€ method_main.py      # Entry point for experiments
â”œâ”€â”€ README.md           # This file
â”œâ”€â”€ requirements.txt    # Lists Python package dependencies
â””â”€â”€ run.sh              # Shell script for executing training and evaluation tasks

```

---

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone <repository_url>
cd READER

python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt
```

### 2. Download data and pretrained parameters

Download TRACE Dataset on [HuggingFace](https://huggingface.co/datasets/alimamaTech/TRACE)  and place it under `data/`.

### 3. Data Preprocess

```bash
cd data
python data_preprocess.py
```

### 4. Run an example script

- Option A: Load Pre-trained Weights (Recommended for quick evaluation)

Ensure you have downloaded the pre-trained weights and placed them in the `pretrian_model/` directory. To run the main training script for our model, use:

```bash
# to direct run our model 
python method_main.py --model='reader' --pretrain_remarks='sharedtwotower' --mode='stream' --gpu_id='4' --lr=0.01  --boost_weight=0.1 --ga_loss_weight=0.5 --train_start_day=57 --train_end_day=81.875
```

- Option B: Train from Scratch
The `run.sh` script allows you to train the READER model.
    * Pre-training 
    This stage initializes the model components using historical data with complete labels.
    
  ```bash
  python main.py --model='sharebottom_twotower'  --gpu_id='4' --pretrain_remarks='sharedtwotower' --mode='pretrain' --train_start_day=0 --train_end_day=50 --lr=0.001
  python method_main.py --model='classifier' --mode='pretrain' --gpu_id='4' --pretrain_remarks='classifier' --lr=0.002
  python method_main.py --model='calibrator' --mode='pretrain' --gpu_id='4' --pretrain_remarks='calibrator' --lr=0.001
  ```
    
    * Online Training
    This stage uses the pre-trained model and fine-tunes it on streaming data with delayed and partial feedback.
    
  ```bash
  python method_main.py --model='reader' --pretrain_remarks='sharedtwotower' --mode='stream' --gpu_id='4' --lr=0.01  --boost_weight=0.1 --ga_loss_weight=0.5 --train_start_day=57 --train_end_day=81.875
  ```

More usage examples can be found in the scripts under the `run.sh` file.
